{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate Star Labels (1–5)\n",
        "\n",
        "This notebook generates star labels using `nlptown/bert-base-multilingual-uncased-sentiment` and writes `data/processed/reviews_with_stars.csv`. Cleaning was assessed as unnecessary for this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1 — Environment & imports\n",
        "\n",
        "Ensure `pandas`, `bs4`, `transformers`, and `torch` are importable. If any fail, install via the active `venv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK pandas\n",
            "OK bs4\n",
            "OK transformers\n",
            "OK torch\n",
            "python: c:\\Users\\TARIK\\venv\\Scripts\\python.exe\n",
            "torch: 2.8.0+cu129\n",
            "cuda_available: True\n",
            "cuda: 12.9\n",
            "gpu: NVIDIA GeForce RTX 5060 Laptop GPU\n"
          ]
        }
      ],
      "source": [
        "import importlib\n",
        "mods = [\"pandas\",\"bs4\",\"transformers\",\"torch\"]\n",
        "for m in mods:\n",
        "    try:\n",
        "        importlib.import_module(m)\n",
        "        print(\"OK\", m)\n",
        "    except Exception as e:\n",
        "        print(\"FAIL\", m, \":\", e)\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "import sys, torch, os\n",
        "print(\"python:\", sys.executable)\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"cuda_available:\", torch.cuda.is_available())\n",
        "print(\"cuda:\", torch.version.cuda)\n",
        "print(\"gpu:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2, 3 and 4 — Config\n",
        "\n",
        "Define model id, batch size, input and output paths, and random seed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "c:\\Users\\TARIK\\venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote c:\\Users\\TARIK\\Desktop\\Charles Darwin University\\4 - Year 1 - Semester 2\\IT CODE FAIR\\Data Science Challenge\\data\\generate_stars\\processed\\reviews_with_stars.csv\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
        "import torch\n",
        "\n",
        "import os\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\"\n",
        "\n",
        "# Resolve project base directory (works from project root or notebooks/)\n",
        "CWD = Path.cwd()\n",
        "BASE_DIR = CWD if (CWD / \"data\" / \"generate_stars\" / \"processed\").exists() else CWD.parent\n",
        "if not (BASE_DIR / \"data\" / \"generate_stars\" / \"processed\").exists():\n",
        "    raise FileNotFoundError(\"Could not locate data/generate_stars/processed from current working directory\")\n",
        "\n",
        "class CFG:\n",
        "    MODEL_ID = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "    BATCH_SIZE = 64  # GPU-enabled\n",
        "    IN_PATH = BASE_DIR / \"data\" / \"generate_stars\" / \"processed\" / \"reviews_unified.csv\"\n",
        "    OUT_WITH_STARS = BASE_DIR / \"data\" / \"generate_stars\" / \"processed\" / \"reviews_with_stars.csv\"\n",
        "    SEED = 42\n",
        "\n",
        "# Step 3 — Load data\n",
        "\n",
        "df = pd.read_csv(CFG.IN_PATH)\n",
        "\n",
        "# Step 4 — Generate stars (continuous + integer)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(CFG.MODEL_ID)\n",
        "tokenizer = AutoTokenizer.from_pretrained(CFG.MODEL_ID)\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "pipeline = TextClassificationPipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"sentiment-analysis\",\n",
        "    truncation=True,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "label_to_int = {\"1 star\":1, \"2 stars\":2, \"3 stars\":3, \"4 stars\":4, \"5 stars\":5}\n",
        "\n",
        "stars_float = []\n",
        "stars = []\n",
        "for i in range(0, len(df), CFG.BATCH_SIZE):\n",
        "    texts = df[\"comment\"].iloc[i:i+CFG.BATCH_SIZE].tolist()\n",
        "    dists = pipeline(texts, batch_size=CFG.BATCH_SIZE, truncation=True, return_all_scores=True)\n",
        "    for dist in dists:\n",
        "        ev = sum(label_to_int[d[\"label\"]] * float(d[\"score\"]) for d in dist)\n",
        "        stars_float.append(ev)\n",
        "        stars.append(int(min(5, max(1, round(ev)))))\n",
        "\n",
        "df_out = df.copy()\n",
        "# Keep float (rounded to 1 decimal) and an internal integer for training/EDA\n",
        "df_out[\"stars_float\"] = pd.Series(stars_float).round(1)\n",
        "df_out[\"stars\"] = pd.Series(stars).astype(int)\n",
        "\n",
        "# Persist only float ratings in the CSV\n",
        "cols_to_save = [\"source\", \"place\", \"comment\", \"stars_float\"]\n",
        "import os\n",
        "os.makedirs(CFG.OUT_WITH_STARS.parent, exist_ok=True)\n",
        "df_out[cols_to_save].to_csv(CFG.OUT_WITH_STARS, index=False)\n",
        "print(\"Wrote\", CFG.OUT_WITH_STARS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5 — Averages per place (descending)\n",
        "\n",
        "Compute and display average stars and review counts by `place`, ordered high → low."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                place  avg_stars  num_reviews\n",
            "7            Tjoritja / West MacDonnell National Park   4.539033          269\n",
            "10                   West MacDonnell – Ormiston Gorge   4.396985          398\n",
            "6                          Nitmiluk (Katherine Gorge)   4.391304          506\n",
            "5   Nitmiluk (Katherine Gorge / Nitmiluk National ...   4.312292          301\n",
            "1                        Devils Marbles (Karlu Karlu)   4.257895          380\n",
            "2                                              Kakadu   4.102616          497\n",
            "4                 Kakadu National Park – Gunlom Falls   4.075472          265\n",
            "9                            West MacDonnell Ormiston   3.900000           10\n",
            "0                           Alice Springs Desert Park   3.869219         3265\n",
            "8                                    Uluru-Kata Tjuta   3.628382         3474\n",
            "3                                 Kakadu Gunlom Falls   3.113772          167\n"
          ]
        }
      ],
      "source": [
        "agg = (\n",
        "    df_out\n",
        "    .groupby(\"place\")\n",
        "    .agg(avg_stars=(\"stars\",\"mean\"), num_reviews=(\"stars\",\"size\"))\n",
        "    .reset_index()\n",
        ")\n",
        "agg = agg.sort_values([\"avg_stars\",\"num_reviews\"], ascending=[False, False])\n",
        "print(agg.head(30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6 — Phase 4 Config (training)\n",
        "\n",
        "Configure training outputs and random seed. We’ll train a quick baseline (TF‑IDF + LogisticRegression) for 5‑class star prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "TRAIN_SEED = 42\n",
        "MODEL_DIR = BASE_DIR / \"models\" / \"star_classifier_log\"\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 7 — Stratified split (train/val)\n",
        "\n",
        "Create a stratified train/validation split from `df_out` for supervised training and evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7625, 1907)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    df_out[\"comment\"].astype(str),\n",
        "    df_out[\"stars\"].astype(int),\n",
        "    test_size=0.2,\n",
        "    random_state=TRAIN_SEED,\n",
        "    stratify=df_out[\"stars\"],\n",
        ")\n",
        "len(X_train), len(X_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 8 — Train baseline classifier\n",
        "\n",
        "Train `TF-IDF + LogisticRegression` on the training split.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained baseline classifier.\n"
          ]
        }
      ],
      "source": [
        "clf = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=50000, ngram_range=(1,2)) ),\n",
        "    (\"logreg\", LogisticRegression(max_iter=200, n_jobs=None, C=2.0, class_weight=\"balanced\")),\n",
        "])\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Trained baseline classifier.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 9 — Evaluate (Accuracy, macro F1, Confusion Matrix)\n",
        "\n",
        "Evaluate on the validation set and save the confusion matrix figure to `visualizations/star_confusion_matrix.png`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1      0.500     0.182     0.267        33\n",
            "           2      0.460     0.536     0.495       248\n",
            "           3      0.412     0.432     0.422       324\n",
            "           4      0.592     0.546     0.568       604\n",
            "           5      0.769     0.781     0.775       698\n",
            "\n",
            "    accuracy                          0.605      1907\n",
            "   macro avg      0.547     0.495     0.505      1907\n",
            "weighted avg      0.607     0.605     0.604      1907\n",
            "\n",
            "Accuracy: 0.605138961719979\n",
            "Macro F1: 0.505374262249147\n",
            "Saved confusion matrix to data/generate_stars/visualizations/star_confusion_matrix.png\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "pred_val = clf.predict(X_val)\n",
        "print(classification_report(y_val, pred_val, digits=3))\n",
        "print(\"Accuracy:\", accuracy_score(y_val, pred_val))\n",
        "print(\"Macro F1:\", f1_score(y_val, pred_val, average=\"macro\"))\n",
        "\n",
        "cm = confusion_matrix(y_val, pred_val, labels=[1,2,3,4,5])\n",
        "os.makedirs(BASE_DIR / \"data\" / \"generate_stars\" / \"visualizations\", exist_ok=True)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            xticklabels=[1,2,3,4,5], yticklabels=[1,2,3,4,5])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Star Classifier - Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(BASE_DIR / \"data\" / \"generate_stars\" / \"visualizations\" / \"star_confusion_matrix.png\")\n",
        "plt.close()\n",
        "print(\"Saved confusion matrix to data/generate_stars/visualizations/star_confusion_matrix.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 10 — Save trained model\n",
        "\n",
        "Persist the trained baseline pipeline to `models/star_classifier/model.joblib` for reuse.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: c:\\Users\\TARIK\\Desktop\\Charles Darwin University\\4 - Year 1 - Semester 2\\IT CODE FAIR\\Data Science Challenge\\models\\star_classifier_log\\model.joblib\n"
          ]
        }
      ],
      "source": [
        "out_model_path = MODEL_DIR / \"model.joblib\"\n",
        "joblib.dump(clf, out_model_path)\n",
        "print(\"Saved:\", out_model_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 11 — Re‑score all comments with the trained classifier\n",
        "\n",
        "Use the trained baseline to predict stars for every comment and write `data/processed/reviews_with_stars_trained.csv`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote c:\\Users\\TARIK\\Desktop\\Charles Darwin University\\4 - Year 1 - Semester 2\\IT CODE FAIR\\Data Science Challenge\\data\\generate_stars\\processed\\reviews_with_stars_trained.csv\n"
          ]
        }
      ],
      "source": [
        "# Reload full dataset comments and predict with trained baseline\n",
        "full_comments = df[\"comment\"].astype(str)\n",
        "trained_preds = clf.predict(full_comments)\n",
        "\n",
        "df_trained = df.copy()\n",
        "df_trained[\"stars\"] = trained_preds\n",
        "import os\n",
        "os.makedirs((BASE_DIR / \"data\" / \"generate_stars\" / \"processed\"), exist_ok=True)\n",
        "out_trained = BASE_DIR / \"data\" / \"generate_stars\" / \"processed\" / \"reviews_with_stars_trained.csv\"\n",
        "df_trained.to_csv(out_trained, index=False)\n",
        "print(\"Wrote\", out_trained)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 12 — Averages by place (trained labels)\n",
        "\n",
        "Compute and display average stars and review counts by `place` using the trained labels (descending), so you can compare with the pretrained averages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                place  avg_stars  num_reviews\n",
            "7            Tjoritja / West MacDonnell National Park   4.583643          269\n",
            "6                          Nitmiluk (Katherine Gorge)   4.416996          506\n",
            "10                   West MacDonnell – Ormiston Gorge   4.374372          398\n",
            "5   Nitmiluk (Katherine Gorge / Nitmiluk National ...   4.335548          301\n",
            "1                        Devils Marbles (Karlu Karlu)   4.231579          380\n",
            "2                                              Kakadu   4.134809          497\n",
            "4                 Kakadu National Park – Gunlom Falls   4.037736          265\n",
            "0                           Alice Springs Desert Park   3.837672         3265\n",
            "8                                    Uluru-Kata Tjuta   3.565630         3474\n",
            "9                            West MacDonnell Ormiston   3.500000           10\n",
            "3                                 Kakadu Gunlom Falls   3.041916          167\n"
          ]
        }
      ],
      "source": [
        "agg_tr = (\n",
        "    df_trained\n",
        "    .groupby(\"place\")\n",
        "    .agg(avg_stars=(\"stars\",\"mean\"), num_reviews=(\"stars\",\"size\"))\n",
        "    .reset_index()\n",
        ")\n",
        "agg_tr = agg_tr.sort_values([\"avg_stars\",\"num_reviews\"], ascending=[False, False])\n",
        "print(agg_tr.head(30))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv (Data Science Challenge)",
      "language": "python",
      "name": "data-challenge-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
