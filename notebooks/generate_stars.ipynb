{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate Star Labels (1–5)\n",
        "\n",
        "This notebook generates star labels using `nlptown/bert-base-multilingual-uncased-sentiment` and writes `data/processed/reviews_with_stars.csv`. Cleaning was assessed as unnecessary for this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1 — Environment & imports\n",
        "\n",
        "Ensure `pandas`, `bs4`, `transformers`, and `torch` are importable. If any fail, install via the active `venv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK pandas\n",
            "OK bs4\n",
            "OK transformers\n",
            "OK torch\n",
            "python: c:\\Users\\TARIK\\Desktop\\Charles Darwin University\\4 - Year 1 - Semester 2\\IT CODE FAIR\\Data Science Challenge\\venv\\Scripts\\python.exe\n",
            "torch: 2.8.0+cu129\n",
            "cuda_available: True\n",
            "cuda: 12.9\n",
            "gpu: NVIDIA GeForce RTX 5060 Laptop GPU\n"
          ]
        }
      ],
      "source": [
        "import importlib\n",
        "mods = [\"pandas\",\"bs4\",\"transformers\",\"torch\"]\n",
        "for m in mods:\n",
        "    try:\n",
        "        importlib.import_module(m)\n",
        "        print(\"OK\", m)\n",
        "    except Exception as e:\n",
        "        print(\"FAIL\", m, \":\", e)\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "import sys, torch, os\n",
        "print(\"python:\", sys.executable)\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"cuda_available:\", torch.cuda.is_available())\n",
        "print(\"cuda:\", torch.version.cuda)\n",
        "print(\"gpu:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2, 3 and 4 — Config\n",
        "\n",
        "Define model id, batch size, input and output paths, and random seed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "c:\\Users\\TARIK\\Desktop\\Charles Darwin University\\4 - Year 1 - Semester 2\\IT CODE FAIR\\Data Science Challenge\\venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote c:\\Users\\TARIK\\Desktop\\Charles Darwin University\\4 - Year 1 - Semester 2\\IT CODE FAIR\\Data Science Challenge\\data\\generate_stars\\processed\\reviews_with_stars.csv\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
        "import torch\n",
        "\n",
        "import os\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\"\n",
        "\n",
        "# Resolve project base directory (works from project root or notebooks/)\n",
        "CWD = Path.cwd()\n",
        "BASE_DIR = CWD if (CWD / \"data\" / \"generate_stars\" / \"processed\").exists() else CWD.parent\n",
        "if not (BASE_DIR / \"data\" / \"generate_stars\" / \"processed\").exists():\n",
        "    raise FileNotFoundError(\"Could not locate data/generate_stars/processed from current working directory\")\n",
        "\n",
        "class CFG:\n",
        "    MODEL_ID = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "    BATCH_SIZE = 64  # GPU-enabled\n",
        "    IN_PATH = BASE_DIR / \"data\" / \"generate_stars\" / \"processed\" / \"reviews_unified.csv\"\n",
        "    OUT_WITH_STARS = BASE_DIR / \"data\" / \"generate_stars\" / \"processed\" / \"reviews_with_stars.csv\"\n",
        "    SEED = 42\n",
        "\n",
        "# Step 3 — Load data\n",
        "\n",
        "df = pd.read_csv(CFG.IN_PATH)\n",
        "\n",
        "# Step 4 — Generate stars (continuous + integer)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(CFG.MODEL_ID)\n",
        "tokenizer = AutoTokenizer.from_pretrained(CFG.MODEL_ID)\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "pipeline = TextClassificationPipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"sentiment-analysis\",\n",
        "    truncation=True,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "label_to_int = {\"1 star\":1, \"2 stars\":2, \"3 stars\":3, \"4 stars\":4, \"5 stars\":5}\n",
        "\n",
        "stars_float = []\n",
        "stars = []\n",
        "for i in range(0, len(df), CFG.BATCH_SIZE):\n",
        "    texts = df[\"comment\"].iloc[i:i+CFG.BATCH_SIZE].tolist()\n",
        "    dists = pipeline(texts, batch_size=CFG.BATCH_SIZE, truncation=True, return_all_scores=True)\n",
        "    for dist in dists:\n",
        "        ev = sum(label_to_int[d[\"label\"]] * float(d[\"score\"]) for d in dist)\n",
        "        stars_float.append(ev)\n",
        "        stars.append(int(min(5, max(1, round(ev)))))\n",
        "\n",
        "df_out = df.copy()\n",
        "# Keep float (rounded to 1 decimal) and an internal integer for training/EDA\n",
        "df_out[\"stars_float\"] = pd.Series(stars_float).round(1)\n",
        "df_out[\"stars\"] = pd.Series(stars).astype(int)\n",
        "\n",
        "# Persist only float ratings in the CSV\n",
        "cols_to_save = [\"source\", \"place\", \"comment\", \"stars_float\"]\n",
        "import os\n",
        "os.makedirs(CFG.OUT_WITH_STARS.parent, exist_ok=True)\n",
        "df_out[cols_to_save].to_csv(CFG.OUT_WITH_STARS, index=False)\n",
        "print(\"Wrote\", CFG.OUT_WITH_STARS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5 — Averages per place (descending)\n",
        "\n",
        "Compute and display average stars and review counts by `place`, ordered high → low."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                           place  avg_stars  num_reviews\n",
            "5  West MacDonnell National Park   4.446086          677\n",
            "3     Nitmiluk (Katherine Gorge)   4.361834          807\n",
            "1   Devils Marbles (Karlu Karlu)   4.257895          380\n",
            "2                         Kakadu   3.917115          929\n",
            "0      Alice Springs Desert Park   3.869219         3265\n",
            "4               Uluru-Kata Tjuta   3.628382         3474\n"
          ]
        }
      ],
      "source": [
        "# Define place name normalization mapping\n",
        "PLACE_MAPPING = {\n",
        "    'Kakadu National Park – Gunlom Falls': 'Kakadu',\n",
        "    'Kakadu Gunlom Falls': 'Kakadu',\n",
        "    'Nitmiluk (Katherine Gorge / Nitmiluk National Park)': 'Nitmiluk (Katherine Gorge)',\n",
        "    'Tjoritja / West MacDonnell National Park': 'West MacDonnell National Park',\n",
        "    'West MacDonnell – Ormiston Gorge': 'West MacDonnell National Park',\n",
        "    'West MacDonnell Ormiston': 'West MacDonnell National Park'\n",
        "}\n",
        "\n",
        "# Create a copy for display purposes with normalized place names\n",
        "df_display = df_out.copy()\n",
        "df_display['place_normalized'] = df_display['place'].replace(PLACE_MAPPING)\n",
        "\n",
        "# Aggregate using normalized place names\n",
        "agg = (\n",
        "    df_display\n",
        "    .groupby(\"place_normalized\")\n",
        "    .agg(avg_stars=(\"stars\",\"mean\"), num_reviews=(\"stars\",\"size\"))\n",
        "    .reset_index()\n",
        "    .rename(columns={'place_normalized': 'place'})\n",
        ")\n",
        "agg = agg.sort_values([\"avg_stars\",\"num_reviews\"], ascending=[False, False])\n",
        "print(agg.head(30))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
